{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e95a374",
   "metadata": {},
   "source": [
    "# Evaluation of SQLQueryChain for Shipment queries (COSC 304 from Dr. Ramon Lawrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c58eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>simple</th>\n",
       "      <th>medium</th>\n",
       "      <th>complex</th>\n",
       "      <th>total</th>\n",
       "      <th>overall_simple</th>\n",
       "      <th>overall_medium</th>\n",
       "      <th>overall_complex</th>\n",
       "      <th>overall_total</th>\n",
       "      <th>avg_similarity_simple</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_similarity_total</th>\n",
       "      <th>avg_colmatch_simple</th>\n",
       "      <th>avg_colmatch_medium</th>\n",
       "      <th>avg_colmatch_complex</th>\n",
       "      <th>avg_colmatch_total</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SQLQueryChain - SHIPMENT - GPT-4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.98</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.920</td>\n",
       "      <td>11443</td>\n",
       "      <td>1485</td>\n",
       "      <td>12928</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQLQueryChain - SHIPMENT - GPT-3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.925</td>\n",
       "      <td>11443</td>\n",
       "      <td>1667</td>\n",
       "      <td>13110</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           experiment  simple  medium  complex  total  \\\n",
       "0    SQLQueryChain - SHIPMENT - GPT-4       5       6        9     20   \n",
       "1  SQLQueryChain - SHIPMENT - GPT-3.5       5       6        9     20   \n",
       "\n",
       "   overall_simple  overall_medium  overall_complex  overall_total  \\\n",
       "0             0.8          0.6667           0.7778           0.75   \n",
       "1             0.6          0.8333           0.4444           0.60   \n",
       "\n",
       "   avg_similarity_simple  ...  avg_similarity_total  avg_colmatch_simple  \\\n",
       "0                   0.98  ...                 0.905                 0.96   \n",
       "1                   0.92  ...                 0.855                 0.96   \n",
       "\n",
       "   avg_colmatch_medium  avg_colmatch_complex  avg_colmatch_total  \\\n",
       "0               0.8833                0.9222               0.920   \n",
       "1               0.9167                0.9111               0.925   \n",
       "\n",
       "   input_tokens  output_tokens  total_tokens  total_cost  total_time  \n",
       "0         11443           1485         12928        0.43     0:01:15  \n",
       "1         11443           1667         13110        0.04     0:00:24  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load your GPT-4 and GPT-3.5 result JSON files\n",
    "with open(\"./results/12_sql_queries_gpt4_shipment.json\", \"r\") as f:\n",
    "    gpt4_data = json.load(f)[\"queries\"]\n",
    "\n",
    "with open(\"./results/9_sql_queries_gpt3.5_shipment.json\", \"r\") as f:\n",
    "    gpt3_data = json.load(f)[\"queries\"]\n",
    "\n",
    "def detailed_summary(data, experiment_name):\n",
    "    type_counts = {\"simple\": 0, \"medium\": 0, \"complex\": 0}\n",
    "    result_correct = {\"simple\": 0, \"medium\": 0, \"complex\": 0}\n",
    "    \n",
    "    # For averaging similarity and column match scores\n",
    "    similarity_sum = {\"simple\": 0, \"medium\": 0, \"complex\": 0}\n",
    "    column_match_sum = {\"simple\": 0, \"medium\": 0, \"complex\": 0}\n",
    "    \n",
    "    # Token and cost tracking\n",
    "    input_tokens = output_tokens = total_tokens = total_cost = total_time = 0\n",
    "\n",
    "    for q in data:\n",
    "        q_type = q[\"type\"]\n",
    "        type_counts[q_type] += 1\n",
    "\n",
    "        if q[\"result\"]:\n",
    "            result_correct[q_type] += 1\n",
    "\n",
    "        # Add similarity and column match scores\n",
    "        similarity_sum[q_type] += q.get(\"similarity\", 0)\n",
    "        column_match_sum[q_type] += q.get(\"column_matching_index\", 0)\n",
    "\n",
    "        # Token and cost metrics\n",
    "        input_tokens += q.get(\"prompt_tokens\", 0)\n",
    "        output_tokens += q.get(\"completion_tokens\", 0)\n",
    "        total_tokens += q.get(\"total_tokens\", 0)\n",
    "        total_cost += q.get(\"total_cost\", 0)\n",
    "        total_time += q.get(\"time\", 0)\n",
    "\n",
    "    total_queries = sum(type_counts.values())\n",
    "    correct_total = sum(result_correct.values())\n",
    "\n",
    "    def safe_div(n, d):\n",
    "        return round(n / d, 4) if d else 0\n",
    "\n",
    "    # Generate the summary dictionary\n",
    "    return {\n",
    "        \"experiment\": experiment_name,\n",
    "        \n",
    "        # Query counts\n",
    "        \"simple\": type_counts[\"simple\"],\n",
    "        \"medium\": type_counts[\"medium\"],\n",
    "        \"complex\": type_counts[\"complex\"],\n",
    "        \"total\": total_queries,\n",
    "\n",
    "        # Accuracy per type\n",
    "        \"overall_simple\": safe_div(result_correct[\"simple\"], type_counts[\"simple\"]),\n",
    "        \"overall_medium\": safe_div(result_correct[\"medium\"], type_counts[\"medium\"]),\n",
    "        \"overall_complex\": safe_div(result_correct[\"complex\"], type_counts[\"complex\"]),\n",
    "        \"overall_total\": safe_div(correct_total, total_queries),\n",
    "\n",
    "        # Average similarity scores\n",
    "        \"avg_similarity_simple\": safe_div(similarity_sum[\"simple\"], type_counts[\"simple\"]),\n",
    "        \"avg_similarity_medium\": safe_div(similarity_sum[\"medium\"], type_counts[\"medium\"]),\n",
    "        \"avg_similarity_complex\": safe_div(similarity_sum[\"complex\"], type_counts[\"complex\"]),\n",
    "        \"avg_similarity_total\": safe_div(sum(similarity_sum.values()), total_queries),\n",
    "\n",
    "        # Average column match scores\n",
    "        \"avg_colmatch_simple\": safe_div(column_match_sum[\"simple\"], type_counts[\"simple\"]),\n",
    "        \"avg_colmatch_medium\": safe_div(column_match_sum[\"medium\"], type_counts[\"medium\"]),\n",
    "        \"avg_colmatch_complex\": safe_div(column_match_sum[\"complex\"], type_counts[\"complex\"]),\n",
    "        \"avg_colmatch_total\": safe_div(sum(column_match_sum.values()), total_queries),\n",
    "\n",
    "        # Token and cost metrics\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"total_tokens\": total_tokens,\n",
    "        \"total_cost\": round(total_cost, 2),\n",
    "\n",
    "        # Total time formatted as H:M:S\n",
    "        \"total_time\": str(timedelta(seconds=round(total_time)))\n",
    "    }\n",
    "\n",
    "# Create summaries for both experiments\n",
    "gpt4_summary = detailed_summary(gpt4_data, \"SQLQueryChain - SHIPMENT - GPT-4\")\n",
    "gpt3_summary = detailed_summary(gpt3_data, \"SQLQueryChain - SHIPMENT - GPT-3.5\")\n",
    "\n",
    "# Combine into a dataframe and display\n",
    "summary_df = pd.DataFrame([gpt4_summary, gpt3_summary])\n",
    "\n",
    "# Optional: sort by accuracy\n",
    "summary_df = summary_df.sort_values(by=\"overall_total\", ascending=False)\n",
    "\n",
    "# Show the result\n",
    "summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc24378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPT-4</th>\n",
       "      <th>GPT-3.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>SQLQueryChain - SHIPMENT - GPT-4</td>\n",
       "      <td>SQLQueryChain - SHIPMENT - GPT-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_simple</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_medium</th>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_complex</th>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_total</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_similarity_simple</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_similarity_medium</th>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_similarity_complex</th>\n",
       "      <td>0.8778</td>\n",
       "      <td>0.7889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_similarity_total</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_colmatch_simple</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_colmatch_medium</th>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_colmatch_complex</th>\n",
       "      <td>0.9222</td>\n",
       "      <td>0.9111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_colmatch_total</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>11443</td>\n",
       "      <td>11443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output_tokens</th>\n",
       "      <td>1485</td>\n",
       "      <td>1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_tokens</th>\n",
       "      <td>12928</td>\n",
       "      <td>13110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_cost</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time</th>\n",
       "      <td>0:01:15</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   GPT-4  \\\n",
       "experiment              SQLQueryChain - SHIPMENT - GPT-4   \n",
       "simple                                                 5   \n",
       "medium                                                 6   \n",
       "complex                                                9   \n",
       "total                                                 20   \n",
       "overall_simple                                       0.8   \n",
       "overall_medium                                    0.6667   \n",
       "overall_complex                                   0.7778   \n",
       "overall_total                                       0.75   \n",
       "avg_similarity_simple                               0.98   \n",
       "avg_similarity_medium                             0.8833   \n",
       "avg_similarity_complex                            0.8778   \n",
       "avg_similarity_total                               0.905   \n",
       "avg_colmatch_simple                                 0.96   \n",
       "avg_colmatch_medium                               0.8833   \n",
       "avg_colmatch_complex                              0.9222   \n",
       "avg_colmatch_total                                  0.92   \n",
       "input_tokens                                       11443   \n",
       "output_tokens                                       1485   \n",
       "total_tokens                                       12928   \n",
       "total_cost                                          0.43   \n",
       "total_time                                       0:01:15   \n",
       "\n",
       "                                                   GPT-3.5  \n",
       "experiment              SQLQueryChain - SHIPMENT - GPT-3.5  \n",
       "simple                                                   5  \n",
       "medium                                                   6  \n",
       "complex                                                  9  \n",
       "total                                                   20  \n",
       "overall_simple                                         0.6  \n",
       "overall_medium                                      0.8333  \n",
       "overall_complex                                     0.4444  \n",
       "overall_total                                          0.6  \n",
       "avg_similarity_simple                                 0.92  \n",
       "avg_similarity_medium                                  0.9  \n",
       "avg_similarity_complex                              0.7889  \n",
       "avg_similarity_total                                 0.855  \n",
       "avg_colmatch_simple                                   0.96  \n",
       "avg_colmatch_medium                                 0.9167  \n",
       "avg_colmatch_complex                                0.9111  \n",
       "avg_colmatch_total                                   0.925  \n",
       "input_tokens                                         11443  \n",
       "output_tokens                                         1667  \n",
       "total_tokens                                         13110  \n",
       "total_cost                                            0.04  \n",
       "total_time                                         0:00:24  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_df = summary_df.transpose()\n",
    "\n",
    "inverted_df = inverted_df.round(2)\n",
    "\n",
    "#Rename Columns\n",
    "\n",
    "inverted_df.columns = [\"GPT-4\", \"GPT-3.5\"]\n",
    "\n",
    "# Display\n",
    "inverted_df\n",
    "\n",
    "# Simple: Number of simple queries evaluated\n",
    "# Medium: Number of medium queries evaluated\n",
    "# Complex: Number of complex queries evaluated\n",
    "# Total: Total number of queries evaluated\n",
    "# overall_simple: Accuracy of simple queries (i.e. how many of the simple were true/correct)\n",
    "# Overall_medium: Accuracy of medium queries (i.e. how many of the medium were true/correct)\n",
    "# Overall_complex: Accuracy of complex queries (i.e. how many of the complex were true/correct)\n",
    "# Overall_total: Accuracy of all queries (i.e. how many of the total were true/correct)\n",
    "# Avg_similarity_simple: Average similarity score for simple queries\n",
    "# Avg_similarity_medium: Average similarity score for medium queries\n",
    "# Avg_similarity_complex: Average similarity score for complex queries\n",
    "# Avg_similarity_total: Average similarity score for all queries\n",
    "# Avg Colmatch Simple: Average column match score for simple queries\n",
    "# Avg Colmatch Medium: Average column match score for medium queries\n",
    "# Avg Colmatch Complex: Average column match score for complex queries\n",
    "# Avg Colmatch Total: Average column match score for all queries\n",
    "# Input Tokens: Total input tokens used\n",
    "# Output Tokens: Total output tokens generated\n",
    "# Total Tokens: Total tokens used (input + output)\n",
    "# Total Cost: Total cost incurred for the queries\n",
    "# Total Time: Total time taken for all queries in H:M:S format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# inverted_df.to_csv(\"inverted_evaluation_summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
